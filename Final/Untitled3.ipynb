{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a24cf8c836e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0mfeature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_valued_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m self.classifier = learn.DNNClassifier(\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_checkpoints_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Plot a confusion matrix, named cm\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    print(target_type)\n",
    "\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename = os.path.join(path,\"crx.csv\")    \n",
    "df = pd.read_csv(filename,na_values=['NA','?'])\n",
    "\n",
    "# Encode feature vector\n",
    "encode_numeric_zscore(df,'a2')\n",
    "encode_numeric_zscore(df,'s3')\n",
    "encode_numeric_zscore(df,'a8')\n",
    "encode_numeric_zscore(df,'a11')\n",
    "encode_numeric_zscore(df,'a14')\n",
    "encode_numeric_zscore(df,'a15')\n",
    "encode_text_dummy(df, 'a1')\n",
    "encode_text_dummy(df, 'a4')\n",
    "encode_text_dummy(df, 'a5')\n",
    "encode_text_dummy(df, 'a6')\n",
    "encode_text_dummy(df, 'a7')\n",
    "#     encode_text_dummy(df, 'a9')\n",
    "encode_text_dummy(df, 'a10')\n",
    "encode_text_dummy(df, 'a12')\n",
    "encode_text_dummy(df, 'a13')\n",
    "encode_text_dummy(df, 'a9')\n",
    "missing_median(df, 'a2')\n",
    "missing_median(df, 'a14')\n",
    "species = encode_text_index(df,\"a16\")\n",
    "a16 = encode_text_index(df,'a16')\n",
    "num_classes = len(a16)\n",
    "\n",
    "\n",
    "\n",
    "# Create x & y for training\n",
    "\n",
    "# Create the x-side (feature vectors) of the training\n",
    "x, y = to_xy(df,'a16')\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42) \n",
    "\n",
    "# Create a deep neural network with 3 hidden layers\n",
    "\n",
    "def __init__(self,name,hidden_units,num_classes,optimizer,steps):\n",
    "        self.classifier = None\n",
    "        self.model_dir = None\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_classes = num_classes\n",
    "        self.optimizer = optimizer\n",
    "        self.steps = steps\n",
    "        self.name = name\n",
    "        \n",
    "def __str__(self):\n",
    "        return \"ScikitLearnTFDNNClassifier(name='{}',hidden_units={},num_classes={},optimizer={},steps={})\".format(\n",
    "        self.name,self.hidden_units,self.num_classes,self.optimizer,self.steps)\n",
    "\n",
    "def fit(self,x,y):\n",
    "        if self.classifier is None:\n",
    "            self.model_dir = get_model_dir(self.name,True)\n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[1])]\n",
    "self.classifier = learn.DNNClassifier(\n",
    "                model_dir= self.model_dir,\n",
    "                config=tf.contrib.learn.RunConfig(save_checkpoints_secs=30),\n",
    "                hidden_units=self.hidden_units, n_classes=num_classes, feature_columns=feature_columns)\n",
    "self.classifier.fit(x,y,steps=self.steps)\n",
    "        \n",
    "return self\n",
    "\n",
    "# Early stopping\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "# Measure accuracy\n",
    "\n",
    "def predict_proba(self,x):\n",
    "        if self.classifier is None:\n",
    "            raise ValueError('A very specific bad thing happened')\n",
    "\n",
    "        return list(self.classifier.predict_proba(x))\n",
    "\n",
    "pred = classifier.predict_proba(x_test)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "print(\"Numpy array of predictions\")\n",
    "print(pred[0:5])\n",
    "\n",
    "print(\"As percent probability\")\n",
    "(pred[0:5]*100).astype(int)\n",
    "\n",
    "score = metrics.log_loss(y_test, pred)\n",
    "print(\"Log loss score: {}\".format(score))\n",
    "\n",
    "\n",
    "\n",
    "score = metrics.accuracy_score(y, classifier.predict(x))\n",
    "print(\"Final accuracy: {}\".format(score))\n",
    "pred = classifier.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, a16)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, a16, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
