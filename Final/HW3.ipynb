{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'oos_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a65a6044d4a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m \u001b[0moos_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[0moos_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[0moos_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'oos_y' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float64), df.as_matrix([target]).astype(np.float64)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "\n",
    "path = \"./Downloads/\"\n",
    "    \n",
    "filename_train = os.path.join(path,\"train.csv\")\n",
    "filename_test = os.path.join(path,\"test.csv\")\n",
    "filename_submit = os.path.join(path,\"sampleSubmission.csv\")\n",
    "\n",
    "df_train = pd.read_csv(filename_train,na_values=['NA','?'])\n",
    "print(df_train['sales'].dtypes)\n",
    "\n",
    "\n",
    "\n",
    "# Encode feature vector\n",
    "encode_text_dummy(df_train, 'type_name')\n",
    "encode_numeric_zscore(df_train,'0_type_count')\n",
    "encode_numeric_zscore(df_train,'1_type_count')\n",
    "encode_numeric_zscore(df_train,'2_type_count')\n",
    "encode_numeric_zscore(df_train,'3_type_count')\n",
    "encode_numeric_zscore(df_train,'4_type_count')\n",
    "encode_numeric_zscore(df_train,'age')\n",
    "encode_numeric_zscore(df_train,'sqft')\n",
    "encode_numeric_zscore(df_train,'income')\n",
    "encode_numeric_zscore(df_train,'pets')\n",
    "encode_numeric_zscore(df_train,'population')\n",
    "encode_numeric_zscore(df_train,'sqmiles')\n",
    "encode_numeric_zscore(df_train,'urban')\n",
    "\n",
    "\n",
    "df_train.drop('id', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Create x & y for training\n",
    "\n",
    "# Create the x-side (feature vectors) of the training\n",
    "\n",
    "x, y = to_xy(df_train, 'sales')\n",
    "    \n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "regressor = Sequential()\n",
    "#regressor.add(Dense(100, input_dim=x.shape[1],activation='relu'))\n",
    "#regressor.add(Dense(50, activation='relu'))\n",
    "regressor.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "regressor.add(Dense(1))\n",
    "regressor.add(Dense(y.shape[1],activation='softmax'))\n",
    "regressor.compile(loss='mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, verbose=1, mode='auto')\n",
    "regressor.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=100000)\n",
    "\n",
    "# Measure RMSE error, for out of sample.\n",
    "pred = regressor.predict(x_test)\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "score = np.sqrt(score)\n",
    "pred = regressor.predict(x_test)\n",
    "\n",
    "oos_y.append(y_test)\n",
    "oos_pred.append(pred)  \n",
    "oos_x.append(x_test)\n",
    "\n",
    "# Measure accuracy\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"RMSE Score:\".format(score))\n",
    "# Generate Kaggle submit file\n",
    "\n",
    "# Encode feature vector\n",
    "df_test = pd.read_csv(filename_test,na_values=['NA','?'])\n",
    "encode_text_dummy(df_test, 'type_name')\n",
    "encode_numeric_zscore(df_test,'0_type_count')\n",
    "encode_numeric_zscore(df_test,'1_type_count')\n",
    "encode_numeric_zscore(df_test,'2_type_count')\n",
    "encode_numeric_zscore(df_test,'3_type_count')\n",
    "encode_numeric_zscore(df_test,'4_type_count')\n",
    "encode_numeric_zscore(df_test,'age')\n",
    "encode_numeric_zscore(df_test,'sqft')\n",
    "encode_numeric_zscore(df_test,'income')\n",
    "encode_numeric_zscore(df_test,'pets')\n",
    "encode_numeric_zscore(df_test,'population')\n",
    "encode_numeric_zscore(df_test,'sqmiles')\n",
    "encode_numeric_zscore(df_test,'urban')\n",
    "\n",
    "ids = df_test['id']\n",
    "df_test.drop('id', axis=1, inplace=True)\n",
    "\n",
    "x = df_test.as_matrix().astype(np.float32)\n",
    "\n",
    "# Generate predictions\n",
    "pred = model.predict(x)\n",
    "#pred\n",
    "\n",
    "# Create submission data set\n",
    "\n",
    "df_submit = pd.DataFrame(pred)\n",
    "df_submit.insert(0,'id',ids)\n",
    "df_submit.columns = ['id','sales']\n",
    "\n",
    "df_submit.to_csv(filename_submit, index=False)\n",
    "\n",
    "print(df_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
