{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangfeiyang/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Question 1***\n",
      "Wrote 10000 lines.\n",
      "\n",
      "***Question 2***\n",
      "Epoch 00253: early stopping\n",
      "Final score (RMSE): 28.79257583618164\n",
      "\n",
      "***Question 3***\n",
      "length: (5.4895, 2.8474024162474727)\n",
      "width:(5.4783, 2.8547055968006094)\n",
      "height:(5.52, 2.872981970451614)\n",
      "     height    length     width\n",
      "0 -0.877137 -1.576700 -1.218444\n",
      "1 -0.180997 -0.874306 -1.218444\n",
      "2 -0.877137 -0.523108 -1.568743\n",
      "\n",
      "***Question 4***\n",
      "Fold #1\n",
      "Epoch 00110: early stopping\n",
      "Fold score (RMSE): 0.18533986806869507\n",
      "Fold #2\n",
      "Epoch 00039: early stopping\n",
      "Fold score (RMSE): 0.1815733164548874\n",
      "Fold #3\n",
      "Epoch 00112: early stopping\n",
      "Fold score (RMSE): 0.1905587762594223\n",
      "Fold #4\n",
      "Epoch 00085: early stopping\n",
      "Fold score (RMSE): 0.2145203948020935\n",
      "Fold #5\n",
      "Epoch 00094: early stopping\n",
      "Fold score (RMSE): 0.2075815051794052\n",
      "Final, out of sample score (RMSE): 0.19633719325065613\n",
      "\n",
      "***Question 5***\n",
      "Fold #1\n",
      "Epoch 00250: early stopping\n",
      "Fold score: 0.975\n",
      "Fold #2\n",
      "Epoch 00124: early stopping\n",
      "Fold score: 0.975\n",
      "Fold #3\n",
      "Epoch 00121: early stopping\n",
      "Fold score: 0.975\n",
      "Fold #4\n",
      "Epoch 00125: early stopping\n",
      "Fold score: 0.8607594936708861\n",
      "Fold #5\n",
      "Epoch 00065: early stopping\n",
      "Fold score: 0.8227848101265823\n",
      "Final, out of sample score: 0.9221105527638191\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for - red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable. The new columns (which - do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the - target_values. One column is added for\n",
    "#eachtargetvalue.\n",
    "def defencode_text_single_dummy(df,name,target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "#Encodetextvaluestoindexes(i.e.[1],[2],[3]forred,green,blue).\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "#Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "    \n",
    "    \n",
    "#Convert all missing values in thes pecified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Encode the toy dataset\n",
    "\n",
    "# Question 1\n",
    "print()\n",
    "print(\"***Question 1***\")\n",
    "path = \"./data/\"\n",
    "filename_read = os.path.join(path,\"toy1.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "filename_write = os.path.join(path,\"submit-FeiyangYang-prog2q1.csv\")\n",
    "\n",
    "#Solution\n",
    "encode_numeric_zscore(df, 'length') \n",
    "encode_numeric_zscore(df, 'width') \n",
    "encode_numeric_zscore(df, 'height') \n",
    "encode_text_dummy(df, 'metal') \n",
    "encode_text_dummy(df, 'shape')\n",
    "    \n",
    "df.to_csv(filename_write,index=False)\n",
    "print(\"Wrote {} lines.\".format(len(df)))\n",
    "\n",
    "\n",
    "#Question 2\n",
    "print()\n",
    "print(\"***Question 2***\")\n",
    "path = \"./data/\"\n",
    "filename_read = os.path.join(path,\"toy1.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "# JTH - The following are from the skeleton code\n",
    "encode_numeric_zscore(df, 'length')\n",
    "encode_numeric_zscore(df, 'width')\n",
    "encode_numeric_zscore(df, 'height')\n",
    "encode_text_dummy(df, 'metal')\n",
    "encode_text_dummy(df, 'shape')\n",
    "\n",
    "#weight = encode_text_index(df,\"weight\") #JTH - do not encode weight (see hint on Schoology)\n",
    "x,y = to_xy(df,'weight') # Create x(predictors) and y (expected outcome)\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "# Create the x/y\n",
    "x, y = to_xy(df, 'weight')\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a deep neural network with 3 hidden layers\n",
    "# of 50, 25, 10\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(100, input_dim=x.shape[1],activation='relu'))\n",
    "regressor.add(Dense(50, activation='relu'))\n",
    "regressor.add(Dense(25, activation='relu'))\n",
    "regressor.add(Dense(1, kernel_initializer='normal'))\n",
    "regressor.compile(loss='mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, verbose=1, mode='auto')\n",
    "regressor.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=100000)\n",
    "\n",
    "# Measure RMSE error, for out of sample.\n",
    "pred = regressor.predict(x_test)\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "score = np.sqrt(score)\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Question 3\n",
    "print()\n",
    "print(\"***Question 3***\")\n",
    "path = \"./data/\"\n",
    "    \n",
    "filename_read = os.path.join(path,\"toy1.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "filename_write = os.path.join(path,\"submit-FeiyangYang-prog2q3.csv\")\n",
    "\n",
    "length_std=df['length'].std()\n",
    "width_std=df['width'].std()\n",
    "height_std=df['height'].std()\n",
    "length_mean=df['length'].mean()\n",
    "width_mean=df['width'].mean()\n",
    "height_mean=df['height'].mean()\n",
    "\n",
    "testDF = pd.DataFrame([\n",
    "            {'length':1, 'width':2, 'height': 3},\n",
    "            {'length':3, 'width':2, 'height': 5},\n",
    "            {'length':4, 'width':1, 'height': 3}\n",
    "         ])\n",
    "    \n",
    "encode_numeric_zscore(testDF,'length',mean=length_mean,sd=length_std)\n",
    "encode_numeric_zscore(testDF,'width',mean=width_mean,sd=width_std)\n",
    "encode_numeric_zscore(testDF,'height',mean=height_mean,sd=height_std)\n",
    "\n",
    "print(\"length: ({}, {})\".format(length_mean,length_std))\n",
    "print(\"width:({}, {})\".format(width_mean,width_std))\n",
    "print(\"height:({}, {})\".format(height_mean,height_std))\n",
    "    \n",
    "print(testDF)\n",
    "    \n",
    "testDF.to_csv(filename_write,index=False)    \n",
    "\n",
    "#Question 4\n",
    "print()\n",
    "print(\"***Question 4***\")\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"iris.csv\")\n",
    "filename_write = os.path.join(path,\"submit-FeiyangYang-prog2q4.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "name = ['species', 'sepal_l', 'sepal_w',  'petal_l','petal_w']\n",
    "df = pd.DataFrame(df[name])\n",
    " \n",
    "np.random.seed(42)\n",
    "\n",
    "encode_numeric_zscore(df,'petal_l')\n",
    "encode_numeric_zscore(df,'sepal_w')\n",
    "encode_numeric_zscore(df,'sepal_l')\n",
    "encode_text_dummy(df,\"species\")\n",
    "\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "x, y = to_xy(df,'petal_w')\n",
    "\n",
    "#Cross validate\n",
    "kf = KFold(5)\n",
    "\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "oos_x = []\n",
    "fold = 1\n",
    "\n",
    "for train, test in kf.split(x):        \n",
    "    print(\"Fold #{}\".format(fold))\n",
    "    fold+=1\n",
    "\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(10, input_dim=x.shape[1],activation='relu'))\n",
    "    regressor.add(Dense(20, activation='relu'))\n",
    "    regressor.add(Dense(10, activation='relu'))\n",
    "    regressor.add(Dense(1, kernel_initializer='normal'))\n",
    "    regressor.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1)\n",
    "    regressor.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=500)\n",
    "    \n",
    "    pred = regressor.predict(x_test)\n",
    "\n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)  \n",
    "    oos_x.append(x_test)\n",
    "\n",
    "    # Get accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_x = np.concatenate(oos_x)\n",
    "   \n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oos_x = pd.DataFrame(oos_x)\n",
    "oos_x.insert(3,'petal_w',oos_y[:])\n",
    "oosDF = pd.concat([oos_x,oos_y, oos_pred],axis=1 )\n",
    "oosDF.columns = ['sepal_l','sepal_w','petal_l','petal_w','species-Iris-setosa','species-Iris-versicolor','species-Iris-virginica',0,0]\n",
    "\n",
    "oosDF.to_csv(filename_write,index=False)\n",
    "\n",
    "#Question 5\n",
    "print()\n",
    "print(\"***Question 5***\")\n",
    "\n",
    "filename_read = os.path.join(path, \"auto-mpg.csv\")\n",
    "filename_write = os.path.join(path, \"submit-FeiyangYang-prog2q5.csv\")\n",
    "df = pd.read_csv(filename_read)\n",
    "df = pd.read_csv(filename_read, na_values=['NA', '?'])\n",
    "\n",
    "# Handle missing values in horsepower\n",
    "missing_median(df, 'horsepower')\n",
    "\n",
    "# Convert to zscores\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "encode_numeric_zscore(df, 'mpg')\n",
    "encode_numeric_zscore(df, 'origin')\n",
    "df.drop('name',1,inplace=True)\n",
    "\n",
    "cyl = encode_text_index(df,'cylinders')\n",
    "num_classes = len(cyl)\n",
    "\n",
    "# Create the x/y\n",
    "x, y = to_xy(df, 'cylinders')\n",
    "\n",
    "# Cross validate\n",
    "kf = KFold(5)\n",
    "\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 1\n",
    "for train, test in kf.split(x):\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "    fold += 1\n",
    "\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # layers of 10, 20, 5\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(y.shape[1],activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "\n",
    "    # Add the predictions to the oos prediction list\n",
    "    pred = model.predict(x_test)\n",
    "    pred = np.argmax(pred,axis=1)\n",
    "\n",
    "    y_compare = np.argmax(y_test,axis=1) \n",
    "    oos_y.append(y_compare)\n",
    "    oos_pred.append(pred)\n",
    "\n",
    "    # Measure accuracy\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(\"Fold score: {}\".format(score))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y = np.concatenate(oos_y)\n",
    "\n",
    "score = metrics.accuracy_score(oos_y, oos_pred)\n",
    "print(\"Final, out of sample score: {}\".format(score))\n",
    "\n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "col_actual = pd.DataFrame(cyl[oos_y])\n",
    "col_predict = pd.DataFrame(cyl[oos_pred])\n",
    "oosDF = pd.concat([df, col_actual, col_predict], axis=1)\n",
    "oosDF.columns = list(df.columns) + ['ideal', 'predict']\n",
    "oosDF.to_csv(filename_write, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
